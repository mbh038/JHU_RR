y
z<-c(1.1,9,3.14)
?c
z
c(z,555,z)
z*2+100
my_sqrt<-sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1,2,3,4)+c(0,10,100)
z*2+1000
my_div
getwd()
ls()
x<-9
ls()
list.files()
?list.files
args(list.files)
old.dir<-getwd()
dir.create(testdir)
?dir.create
setwd("H:/Rspace")
dir.create(H:/Rspace/testdir)
dir.create("H:/Rspace/testdir")
dir.create("testdir")
setwd("testdir")
file.create("mytest.R")
list.files()
file.exists("mytest.R")
file.info("mytest.R)
file.info("mytest.R")
?file.rename
file.rename("mytest.R","mytest2.R")
file.copy("mytest2.R","mytest3.R")
file.path("mytest3.R")
play()
?file.path
nxt()
file.path(folder1/folder2)
file.path(folder1,folder2)
file.path("folder1","folder2")
play()
getwd()
nxt()
?dir.create
dir.create(file.path("testdir2","testdir3"),recursive=TRUE)
unlink("testdir2",recursive=TRUE)
setwd(olddir)
setwd("olddir")
setwd(old.dir)
unlink("testdir",recursive=TRUE)
1:20
pi:10
15:1
?`:`
seq(1,20)
seq(0,10,by=0.5)
seq(5,10,length=30)
my_seq<-seq(5,10,length=30)
length(my_seq)
1:length(my_seq)
seq(along.with=my_seq)
seq_along(my_seq)
rep(0,times=40)
rep(c(0,1,2),times=10)
rep(c(0,1,2),each=10)
num_vect<-c(0.5,55,-10,6)
tf<-num_vect<1
tf
num_vect>=6
my_char<-c("My","name","is")
my_char
paste(my_char,collapse=" ")
my)name<-c(my_char,"Mike")
my_name<-c(my_char,"Mike")
my_name
paste(my_name,collapse=" ")
paste9"Hello","World",sep=" ")
paste("Hello","World",sep=" ")
paste("Hello","World!",sep=" ")
paste("Hello","world!",sep=" ")
paste(1:3,c("X","Y","Z"),sep="")
paste(LETTERS,1:4,sep="-")
library("swirl", lib.loc="\\cam-stf-fs1/users/michael.hunt/my documents/R/win-library/3.1")
swirl()
librsry(swirl)
library(swirl)
swirl()
swirl()
sapply(flags,unique)
vapply(flags,unique,numeric(1))
ok()
sapply(flags,class)
vaply(falgs,class,character(1))
vapply(falgs,class,character(1))
vapply(flags,class,character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(falgs$animate,flags$landmass,mean)
tapply(flags$animate,flags$landmass,mean)
tapply(flags$population,flags$red,summary)
tapply(flags$population,flags$landmass,summary)
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants,10)
tail(plants,15
)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample()
?sample
sample(1:6,4,replace=TRUE)
play()
sample(1:6,4,replace=FALSE)
sample(1:6,6,replace=FALSE)
sample(1:6,7,replace=FALSE)
sample(1:6,7,replace=TRUE)
nxt()
sample(1:6,4,replace=TRUE)
sample(1:20,10)
LETTERS
letters
sample(LETTERS)
sample(c(0,1),100,prob=c(0.3,0.7))
flips<-sample(c(0,1),100,prob=c(0.3,0.7),replace=TRUE)
flips
sum(flips)
?rbinom
rbinom(1,size=100,prob=0.7)
rbinom(100,size=1,prob=0.7)
flip2<-rbinom(100,size=1,prob=0.7)
flips2<-rbinom(100,size=1,prob=0.7)
flips2
sum(flips2)
?rnorm
rnorm(10)
rnorm(100,25)
rnorm(10,100,25)
?rpois
rpois(5,10)
my_pois<-replicate(100,rpois(5,10))
my_pois
cm<-colmeans(my_pois)
cm<-colMeans(my_pois)
hist(cm)
dl<-Sys.Date()
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
as.POSIXlt(Sys.time())
t2<-as.POSIXlt(Sys.time())
class(t2)
unclass(t2)
t2
unclass(t2)
str(unclass(t2)
)
t2$min
weekdays(t1)
weekdays(d1)
months(t1)
quarters(t2)
t3<-"October 17,1986 08:24"
t3<-"October 17,1986, 08:24"
t3<-"October 17, 1986 08:24"
t4<-strptime(t3,"%B,%d,%Y %H;%M")
t4<-strptime(t3,"%B %d,%Y %H;%M")
t4<-strptime(t3,"%B %d,%Y %H:%M")
t4<-strptime(t3, "%B %d, %Y %H:%M")
print(t4)
t4
class(t4)
Sys.time()>t1
Sys.time(0-t1)
Sys.time()-t1
difftime(Sys.time(),t1,units='days')
data(cars)
help(cars)
head(cars)
plot(cars)
?plot
plot(x=cars$speed,y=cars$dist)
plot(x=cars$dist,y=cars$speed)
plot(x=cars$speed,y=cars$dist)
plot(x=cars$speed,y=cars$dist,Xlab="Speed")
plot(x=cars$speed,y=cars$dist,xlab="Speed")
plot(x=cars$speed,y=cars$dist,xlab="Speed",ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,ylab="Stopping Distance")
plot(x=cars$speed,y=cars$dist,xlab="Speed",ylab="Stopping Distance")
plot(cars,Title="My Plot")
plot(cars,main="My Plot")
play()
?plot
nxt()
plot(cars,sub="My Plot Subtitle")
asa
plot(cars)
plot(cars,col=2)
plot(cars,xlim=c(10,15))
plot(cars,pch=2)
data(mtcars)
play()
dim(mtcars)
str(mtcars)
summary(mtcars)
names(mtcars)
class(mtcars)
nxt()
?boxplot
boxplot(mpg~cyl,data=mtcars)
hist(mtcars$mpg)
f<-function(x){}
my.vec<-c(NA,0,2,3,4,NA)
min(my.vec)
install.packages(lubridate)
install.packages("lubridate")
library(lubridate)
ymd("20140108")
ymd("20140108")
mdy("05072015")
setwd(H:/Rspace/JHU_Data_Science/JHU_RR/PA2)
setwd("H:/Rspace/JHU_Data_Science/JHU_RR/PA2")
install.packages("data.table")
# then we cycle through the EVTYPE column in our reduced set and allocate each row to  whichever (If any) of the above categories contains it.
f<-function(x){
s<-grepl(x,sd.red$EVTYPE,ignore.case=TRUE)
}
t<-sapply(evtype[1:length(evtype)],f)
evtype.recorded<-length(unique(sd.red$EVTYPE))
str(stormdata)
#check for NAs
mean(is.na(stormdata$FATALITIES))
mean(is.na(stormdata$INJURIES))
mean(is.na(stormdata$PROPDMG))
mean(is.na(stormdata$CROPDMG))
if(!file.exists("./data/stormData.csv.bz2")){
fileURL<-"http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
download.file(fileURL,destfile="./data/stormData.csv.bz2")
#include date of download
datedownloaded<-date()
datedownloaded
}
# using cache here causes memory overlaod in my computer!
# To do: find a faster way to read the data into R.
file<- bzfile(description = "./data/stormData.csv.bz2", open = 'r', encoding =
getOption('encoding'), compression = 9)
stormdata <- read.csv(file, header = TRUE, stringsAsFactors = FALSE)
# Data Processing
### Initial Inspection of the data
```{r}
str(stormdata)
#check for NAs
mean(is.na(stormdata$FATALITIES))
mean(is.na(stormdata$INJURIES))
mean(is.na(stormdata$PROPDMG))
mean(is.na(stormdata$CROPDMG))
```
There are no NAs in these relevant data columns. Yay!
### Reduce the size of the data set
```{r select only the columns we need}
library(dplyr)
df1 <-select(stormdata,STATE__:EVTYPE,FATALITIES:CROPDMGEXP)
str(df1)
```
```{r filter out null EVTYPE rows}
df2<-filter(df1,FATALITIES+INJURIES+PROPDMG+CROPDMG>0 )
str(df2)
```
```{r extract year from the BGN_DATE column}
library(lubridate)
year<-as.POSIXlt(mdy_hms(df2$BGN_DATE))
year<-year$year+1900
summary(year) # check this looks OK.
# include this column in the reduced data set df2
sd.red<-data.frame(year,df2)
```
```{r annual totals of fatalities and injuries}
fit.i<-aggregate(sd.red$INJURIES,by=list(sd.red$year),FUN="sum")
fit.f<-aggregate(sd.red$FATALITIES,by=list(sd.red$year),FUN="sum")
fit<-data.frame(fit.i$Group.1,fit.i$x+fit.f$x)
summary(fit)
names(fit)[names(fit)=="fit.i.Group.1"] <- "Year"
names(fit)[names(fit)=="fit.i.x...fit.f.x"] <- "Fatalities.Injuries"
```
```{r annual totals of damage value}
pt<-aggregate(sd.red$PROPDMG,by=list(sd.red$year),FUN="sum")
ct<-aggregate(sd.red$CROPDMG,by=list(sd.red$year),FUN="sum")
pct<-data.frame(pt$Group.1,pt$x+ct$x)
summary(pct)
names(pct)[names(pct)=="pt.Group.1"] <- "Year"
names(pct)[names(pct)=="pt.x...ct.x"] <- "Totals"
```
Merge these two totals together
```{r}
annual.totals<-fit
annual.totals$Damage<-pct$Totals
#names(annual.totals)[names(annual.totals)=="pct$Total.Damage"] <- "Total.Damage"
str(annual.totals)
```
Exploratory analysis of these annual totals
```{r}
library(ggplot2)
par(mfrow = c(1, 2))
par(mar = c(3, 4,3,1))
par(bg="white")
with(annual.totals,plot(Year,Fatalities.Injuries,
xlim=c(1950,2020),
ylim=c(0,max(annual.totals$Fatalities.Injuries)),
xlab="Year",
ylab="Annual fatalities and Injuries",
pch=19,
col="red",
#main="Fatalities / Injuries"
)
)
with(annual.totals,plot(Year,Damage,
xlim=c(1950,2020),
ylim=c(0,max(annual.totals$Damage)),
xlab="Year",
ylab="Annual crop damage",
pch=19,
col="blue",
#main="Property and crop damage ($)"
)
)
```{r}
```
```
We note a huge rise in fatalities and injuries from about 1990 onwards. This probably reflects a rise in the available volume of data, rather than an actual rise'
We could investigate this here:
### Analysis by type
How many types of event have been recorded?
```{r}
evtype.recorded<-length(unique(sd.red$EVTYPE))
```
The number of ditinct event types recorded in the data set is `r evtype.recorded`. This is far greater than the 46 distinct event types recognised by NOAA.
We will try and allocate as many as possible of the recorded event types to **one** of these official categories. If the total number captured is a high proportion of the total set, it will be prepresentative of the whole.
### Allocation of event categories.
#First, we construct a character vector that contains these category names as written
# in the NOAA documentation:
```r{}
evtype<-c("Astronomical Low Tide","Avalanche","Blizzard","Coastal Flood","Cold/Wind Chill","Debris Flow","Dense Fog","Dense Smoke","Drought","Dust Devil","Dust Storm","Excessive Heat","Extreme Cold/Wind Chill","Flash Flood","Flood","Frost/Freeze","Funnel Cloud","Freezing Fog","Hail","Heat","Heavy Snow","High Surf","High Wind","Hurricane (Typhoon)","Ice Storm","Lake-Effect Snow","Lakeshore Flood","Lightning","Marine Hail","Marine High Wind","Marine Strong Wind","Marine Thunderstorm Wind","Rip Current","Seiche","Sleet","Storm Surge/Tide","Strong Wind","Thunderstorm Wind","Tornado","Tropical Depression","Tropical Storm","Tsunami","Volcanic Ash","Waterspout","Wildfire","Winter Storm","Winter Weather")
evtype
```
```{r cache=TRUE}
# then we cycle through the EVTYPE column in our reduced set and allocate each row to  whichever (If any) of the above categories contains it.
f<-function(x){
s<-grepl(x,sd.red$EVTYPE,ignore.case=TRUE)
}
t<-sapply(evtype[1:length(evtype)],f)
```
```r{}
# check lengths of each column of t
n.evtype<-colSums(t,na.rm=TRUE)
r.evtype<-rowSums(t,na.rm=TRUE)
sum(n.evtype)
sum(r.evtype[]>1)
```
The number of captured events is `r sum(n.evtype)` from a possible total of `r nrow(sd.dev). This is a large enough sample for conclusions drawn from it to be representativew of the whole data set.
`We now create a column with the reduced type set of type descriptors that we have identified mapped against those actually in EVTYPE.
evtype.recorded<-length(unique(sd.red$EVTYPE))
str(stormdata)
#check for NAs
mean(is.na(stormdata$FATALITIES))
mean(is.na(stormdata$INJURIES))
mean(is.na(stormdata$PROPDMG))
mean(is.na(stormdata$CROPDMG))
library(dplyr)
df1 <-select(stormdata,STATE__:EVTYPE,FATALITIES:CROPDMGEXP)
str(df1)
```{r filter out null EVTYPE rows}
df2<-filter(df1,FATALITIES+INJURIES+PROPDMG+CROPDMG>0 )
str(df2)
```{r filter out null event rows}
df2<-filter(df1,FATALITIES+INJURIES+PROPDMG+CROPDMG>0 )
str(df2)
sumzero=sum(df2$FATALITIES)
sumzero
?is
isTRUE(TRUE)
M(c(1,2,3,4),2,2)
M<-matrix(c(1,2,3,4),2,2)
isTRUE(c(TRUE,FALSE,TRUE))
as.numeric(c(TRUE,FALSE,TRUE))
str(t)
str(sd.red)
"wave"*1
M<matrix(c(1,2,3,4),2,2)
M<-matrix(c(1,2,3,4),2,2)
D<-c(2,3)
str(sd.red)
str(df2)
library(lubridate)
year<-as.POSIXlt(mdy_hms(df2$BGN_DATE))
year<-year$year+1900
summary(year) # check this looks OK.
# include this column in the reduced data set df2
sd.red<-data.frame(year,df2)
str(d.red)
str(sd.red)
```{r annual totals of fatalities and injuries}
fit.i<-aggregate(sd.red$INJURIES,by=list(sd.red$year),FUN="sum")
fit.f<-aggregate(sd.red$FATALITIES,by=list(sd.red$year),FUN="sum")
fit<-data.frame(fit.i$Group.1,fit.i$x+fit.f$x)
summary(fit)
names(fit)[names(fit)=="fit.i.Group.1"] <- "Year"
names(fit)[names(fit)=="fit.i.x...fit.f.x"] <- "Fatalities.Injuries"
```
```{r annual totals of damage value}
pt<-aggregate(sd.red$PROPDMG,by=list(sd.red$year),FUN="sum")
ct<-aggregate(sd.red$CROPDMG,by=list(sd.red$year),FUN="sum")
pct<-data.frame(pt$Group.1,pt$x+ct$x)
summary(pct)
names(pct)[names(pct)=="pt.Group.1"] <- "Year"
names(pct)[names(pct)=="pt.x...ct.x"] <- "Totals"
```
Merge these two totals together
```{r}
annual.totals<-fit
annual.totals$Damage<-pct$Totals
#names(annual.totals)[names(annual.totals)=="pct$Total.Damage"] <- "Total.Damage"
str(annual.totals)
```
Exploratory analysis of these annual totals
```{r}
library(ggplot2)
par(mfrow = c(1, 2))
par(mar = c(3, 4,3,1))
par(bg="white")
with(annual.totals,plot(Year,Fatalities.Injuries,
xlim=c(1950,2020),
ylim=c(0,max(annual.totals$Fatalities.Injuries)),
xlab="Year",
ylab="Annual fatalities and Injuries",
pch=19,
col="red",
#main="Fatalities / Injuries"
)
)
with(annual.totals,plot(Year,Damage,
xlim=c(1950,2020),
ylim=c(0,max(annual.totals$Damage)),
xlab="Year",
ylab="Annual crop damage",
pch=19,
col="blue",
#main="Property and crop damage ($)"
)
)
```{r}
```
```
We note a huge rise in fatalities and injuries from about 1990 onwards. This probably reflects a rise in the available volume of data, rather than an actual rise'
We could investigate this here:
### Analysis by type
How many types of event have been recorded?
```{r}
evtype.recorded<-length(unique(sd.red$EVTYPE))
```
The number of ditinct event types recorded in the data set is `r evtype.recorded`. This is far greater than the 46 distinct event types recognised by NOAA.
We will try and allocate as many as possible of the recorded event types to **one** of these official categories. If the total number captured is a high proportion of the total set, it will be prepresentative of the whole.
### Allocation of event categories.
#First, we construct a character vector that contains these category names as written
# in the NOAA documentation:
```r{}
evtype<-c("Astronomical Low Tide","Avalanche","Blizzard","Coastal Flood","Cold/Wind Chill","Debris Flow","Dense Fog","Dense Smoke","Drought","Dust Devil","Dust Storm","Excessive Heat","Extreme Cold/Wind Chill","Flash Flood","Flood","Frost/Freeze","Funnel Cloud","Freezing Fog","Hail","Heat","Heavy Snow","High Surf","High Wind","Hurricane (Typhoon)","Ice Storm","Lake-Effect Snow","Lakeshore Flood","Lightning","Marine Hail","Marine High Wind","Marine Strong Wind","Marine Thunderstorm Wind","Rip Current","Seiche","Sleet","Storm Surge/Tide","Strong Wind","Thunderstorm Wind","Tornado","Tropical Depression","Tropical Storm","Tsunami","Volcanic Ash","Waterspout","Wildfire","Winter Storm","Winter Weather")
evtype
```
```{r}
# then we cycle through the EVTYPE column in our reduced set and allocate each row to  whichever (If any) of the above categories contains it.
f<-function(x){
s<-grepl(x,sd.red$EVTYPE,ignore.case=TRUE)
}
t<-sapply(evtype[1:length(evtype)],f)
tn<-as.numeric(t)
rm(t)
"a" & 1
"a" & TRUE
"a" && TRUE
matrix("A","B","C,"D",2,2)
matrix("A","B","C","D",2,2)
matrix(c("A","B","C","D"),2,2)
matrix(c(C(1,0,0,1)),2,2)
matrix(c(C(1,0,0,1),2,2)
matrix(c(1,0,0,1),2,2)
v<c(A,B)
v<-c(A,B)
v<-c("A","B")
v
m<-matrix(c(1,0,0,1),2,2)
v*m
v+m
V & m
v & m

---
title: "JHU_RR_PA2"
author: "mbh"
date: "Thursday, May 21, 2015"
output: html_document
---

# Instructions

## Assignment

The basic goal of this assignment is to explore the NOAA Storm Database and answer some basic questions about severe weather events. You must use the database to answer the questions below and show the code for your entire analysis. Your analysis can consist of tables, figures, or other summaries. You may use any R package you want to support your analysis.

## Questions

Your data analysis must address the following questions:

* Across the United States, which types of **events** (as indicated in the EVTYPE variable) are **most harmful with respect to population health**?

* Across the United States, which types of **events** have the **greatest economic consequences**?

Consider writing your report as if it were to be read by a government or municipal manager who might be responsible for preparing for severe weather events and will need to prioritize resources for different types of events. However, there is no need to make any specific recommendations in your report.

# Title

# Synopsis

No more than 10 sentences

... other sections

# Set up
## Set working directory
```{r setwd}
rm(list=ls())
setwd("C:/Users/Mike/Rspace/JHU_RR/PA2") # amend pathway as required
#setwd("H:/Rspace/JHU_Data_Science/JHU_RR/PA2")
```
## Load libraries
```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(data.table)
library(lubridate)
```

# Data Source

The NOAA data for this analysis is taken from the link provided on the JHU Reproducible Research Peer Assignment 2 Coursera site:

[Storm data](https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2,) [47Mb]

Information on this data is available here

National Weather Service [Storm Data Documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf)

National Climatic Data Center Storm Events [FAQ](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2FNCDC%20Storm%20Events-FAQ%20Page.pdf)

We save it into a csv.bz2 file on our local machine


# Download data

### Create data directory if it doesn't already exist
```{r download the file}
if(!file.exists("data")){
        dir.create("data")
}
```

### Download data if not yet already done so
```{r download data file}
if(!file.exists("./data/stormData.csv.bz2")){
        fileURL<-"http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
        download.file(fileURL,destfile="./data/stormData.csv.bz2")
        #include date of download
        datedownloaded<-date()
        datedownloaded     
}
```
### Load data into R
```{r load into R}
# using cache here causes memory overload in my computer!
# To do: find a faster way to read the data into R.
file<- bzfile(description = "./data/stormData.csv.bz2", open = 'r', encoding =
getOption('encoding'), compression = 9)
stormdata <- read.csv(file, header = TRUE, stringsAsFactors = FALSE)
```

# Data Processing

### Initial Inspection of the data

```{r initial inspection}

str(stormdata)

#check for NAs
mean(is.na(stormdata$FATALITIES))
mean(is.na(stormdata$INJURIES))
mean(is.na(stormdata$PROPDMG))
mean(is.na(stormdata$CROPDMG))
# There are no NAs in these relevant data columns. Yay!
```


### Reduce the size of the data set

```{r select only the columns we need}
library(dplyr)
df1 <-select(stormdata,STATE__:EVTYPE,FATALITIES:CROPDMGEXP)
rm(stormdata)
str(df1)
```
```{r filter out null event rows}
df2<-filter(df1,FATALITIES+INJURIES+PROPDMG+CROPDMG>0 )
rm(df1)
str(df2)
```
```{r extract year from the BGN_DATE column}
library(lubridate)
year<-as.POSIXlt(mdy_hms(df2$BGN_DATE))
year<-year$year+1900
summary(year) # check this looks OK.
# include this column in the reduced data set df2
sd.red<-data.frame(year,df2)
rm(df2,year)
```

```{r annual totals of fatalities and injuries}
fit.i<-aggregate(sd.red$INJURIES,by=list(sd.red$year),FUN="sum")
fit.f<-aggregate(sd.red$FATALITIES,by=list(sd.red$year),FUN="sum")
fit<-data.frame(fit.i$Group.1,fit.i$x+fit.f$x)
summary(fit)
names(fit)[names(fit)=="fit.i.Group.1"] <- "Year"
names(fit)[names(fit)=="fit.i.x...fit.f.x"] <- "Fatalities.Injuries"
```
```{r annual totals of damage value}
pt<-aggregate(sd.red$PROPDMG,by=list(sd.red$year),FUN="sum")
ct<-aggregate(sd.red$CROPDMG,by=list(sd.red$year),FUN="sum")
pct<-data.frame(pt$Group.1,pt$x+ct$x)
summary(pct)
names(pct)[names(pct)=="pt.Group.1"] <- "Year"
names(pct)[names(pct)=="pt.x...ct.x"] <- "Totals"
```
Merge these two totals together
```{r}
annual.totals<-fit
annual.totals$Damage<-pct$Totals
rm(fit.i,fit.f,fit,pt,ct,pct) # clean up
#names(annual.totals)[names(annual.totals)=="pct$Total.Damage"] <- "Total.Damage"
str(annual.totals)
```

Exploratory analysis of these annual totals
```{r plot eda figure}
library(ggplot2)

par(mfrow = c(1, 2))
par(mar = c(3, 4,3,1))
par(bg="white")

with(annual.totals,plot(Year,Fatalities.Injuries,
                        xlim=c(1950,2020),
                        ylim=c(0,max(annual.totals$Fatalities.Injuries)),
                        xlab="Year",
                        ylab="Annual fatalities and Injuries",
                        pch=19,
                        col="red",
                        #main="Fatalities / Injuries"
                        )
        )
 with(annual.totals,plot(Year,Damage,
                        xlim=c(1950,2020),
                        ylim=c(0,max(annual.totals$Damage)),
                        xlab="Year",
                        ylab="Annual crop damage",
                        pch=19,
                        col="blue",
                        #main="Property and crop damage ($)"
                        )
        )
           
```
We note a huge rise in fatalities and injuries from about 1990 onwards. This probably reflects a rise in the available volume of data, rather than an actual rise'


We could investigate this here:

### Analysis by type

We wish to identify those weather types that have been most damaging to people, in terms of numbers of fatalities and injuries caused, and to crops and property in economic terms. The categories used will be those recognised by NOAA:

```{r NOAA event type list}
evtype<-c("Astronomical Low Tide","Avalanche","Blizzard","Coastal Flood","Cold/Wind Chill","Debris Flow","Dense Fog","Dense Smoke","Drought","Dust Devil","Dust Storm","Excessive Heat","Extreme Cold/Wind Chill","Flash Flood","Flood","Frost/Freeze","Funnel Cloud","Freezing Fog","Hail","Heat","Heavy Rain","Heavy Snow","High Surf","High Wind","Hurricane","Ice Storm","Lake-Effect Snow","Lakeshore Flood","Lightning","Marine Hail","Marine High Wind","Marine Strong Wind","Marine Thunderstorm Wind","Rip Current","Seiche","Sleet","Storm Surge/Tide","Strong Wind","Thunderstorm Wind","Tornado","Tropical Depression","Tropical Storm","Tsunami","Volcanic Ash","Waterspout","Wildfire","Winter Storm","Winter Weather")
evtype
levtypes<-length(evtype)
```
which number `r levtypes` in all

and the number of event types actually recorded

```{r unique event record types}
evrep<-sd.red$EVTYPE
nevrec<-length(unique(evrep))
```
of which there are `r nevrec` we see that many events must have been recorded with non-standard terms. Hence before final analysis, the recorded events have had to be mapped to one or other of the recognised categories. This has been achieved by a process of matching terms, identifying common alternative terms (eg TSTM for thunderstorm, precipitation for rain etc), and correction of obvious typographical errors eg TORNDAo etc.

The matching process is described below and may be skipped if not of interest. The criterion for this process was that at least 95% of the reported events should be mapped to one NOAA category. Those that could not be mapped were not included in the final analysis.

### Mapping of reported weather events to NOAA categories.

This is an iterative process.

First, we make some substitutions:

* _TSTM_ replaced by _Thunderstorm_
* _Precipitation_ replaced by _Rain_

```{r fix typos etc}
evrep<-sd.red$EVTYPE
evrep<-gsub("Precipitation|drizzle|shower","RAIN",evrep,ignore.case=TRUE)
evrep<-gsub("TSTM|THUNDERESTORM|THUNERSTORM|THUNDEERSTORM|THUNDERTORM",
            "THUNDERSTORM",evrep,ignore.case=TRUE)
evrep<-gsub("STROM","STORM",evrep,ignore.case=TRUE)
evrep<-gsub("TUN","THUN",evrep,ignore.case=TRUE)
evrep<-gsub("THUNDERSTORM\\S","THUNDERSTORM\\s",evrep,ignore.case=TRUE)
evrep<-gsub("STORMS","STORM",evrep,ignore.case=TRUE)
evrep<-gsub("WINDS|WINS","WIND",evrep,ignore.case=TRUE)
evrep<-gsub("Typhoon","Hurricane",evrep,ignore.case=TRUE)
evrep<-gsub("Hurricane\\s[A-z]|Hurricane[A-z]","Hurricane",evrep,ignore.case=TRUE)
evrep<-gsub("ASTRONOMICAL HIGH TIDE","Storm Surge/Tide",evrep,ignore.case=TRUE)
evrep<-gsub("Whirlwind|Torndao","TORNADO",evrep,ignore.case=TRUE)
evrep<-gsub("Lighting|LIGNTNING","Lightning",evrep,ignore.case=TRUE)
evrep<-gsub("Excessive|Hvy|Severe","HEAVY",evrep,ignore.case=TRUE)
```
```{r}
evred<-sapply(1:levtypes,function(x){
        grep(evtype[x],evrep,ignore.case=TRUE)
})
```
```{r}
event<-c(rep("NULL",nrow(sd.red)))
for(i in 1:47){
        event[evred[[i]]]<-evtype[i]
}
```
```{r check missing}
missed<-evrep[grep("NULL",event)]
unique(missed)
length(missed)
length(missed)/length(event)
```
Capture rate is `r length(missed)/length(event)`

This exceeds the threhold of 95% set for completeness of capture.

```{r}
# Add mapped weather type vector to the reduced data set
sd.red<-data.frame(select(sd.red,year:EVTYPE),
                    event,
                    select(sd.red,FATALITIES:CROPDMGEXP),
                    stringsAsFactors=FALSE)
```

## Ranking of Events by Human Impact

```{r human rank}
fatalities<-sd.red %>% group_by(event) %>% summarise(fatalities=sum(FATALITIES))
injuries<-sd.red %>% group_by(event) %>% summarise(injuries=sum(INJURIES))
human<-left_join(fatalities,injuries,by="event")
human<-mutate(human,total=fatalities+injuries)
human<-human %>% mutate(fatalityrank=dense_rank(desc(fatalities)))
human<-human %>% mutate(injuriesrank=dense_rank(desc(injuries)))
human<-human %>% mutate(totalrank=dense_rank(desc(total)))
human
```
```{r human tidy}

```
## Ranking by number of fatalities/Injuries caused



Now we rank the weather event types according to the number of fatalites and injuries caused.

We present results showing both the total and the median values for each of these.


'' other sections

consider cache=TRUE

# Results

Required

At least 1 figure containing a plot

No more than 3 Figures

Include all code. Use echo = TRUE

